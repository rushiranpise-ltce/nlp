{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP EXP2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKEXwj/ZZ9+zIRL+DxNMqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushiranpise-ltce/nlp/blob/main/NLP_EXP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZKhNjJu2Zzl"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update && sudo apt-get upgrade -y\n",
        "!sudo apt-get install python3 python3-pip ipython3 -y\n",
        "!pip3 install jupyter\n",
        "!jupyter notebook --allow-root\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy validate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.blank(\"en\")\n",
        "with open(\"alt.txt\")as f:\n",
        "          text=f.readlines()\n",
        "          print(text)"
      ],
      "metadata": {
        "id": "6NGkoxRz2qZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " text=' '.join(text)\n",
        " print(text)       "
      ],
      "metadata": {
        "id": "kJ2LZc3t3GgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text)\n",
        "emails=[]\n",
        "for token in doc:\n",
        "     if token.like_email:\n",
        "       emails.append(token.text)\n",
        "print(emails)"
      ],
      "metadata": {
        "id": "2O_OE1Za3HF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe('sentencizer')\n",
        "doc=nlp(\"Cybersecurity is the protection of internet-connected systems such as hardware, software and data from cyberthreats. The practice is used by individuals and enterprises to protect against unauthorized access to data centers and other computerized systems.\")\n",
        "for sentence in doc.sents:\n",
        "        print(sentence)"
      ],
      "metadata": {
        "id": "A0ne7tuz9ZQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "print(STOP_WORDS)"
      ],
      "metadata": {
        "id": "Y3kJ1-6bBVba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"in\" in STOP_WORDS\n",
        "\"apple\" in STOP_WORDS"
      ],
      "metadata": {
        "id": "upJp13QgBiJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"A simple pipeline component to allow custom sentence boundary detection logic that doesn’t require the dependency parse. By default, sentence segmentation is performed by the DependencyParser, so the Sentencizer lets you implement a simpler, rule-based strategy that doesn’t require a statistical model to be loaded.\")\n"
      ],
      "metadata": {
        "id": "6HRvj-U_Bzf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "id": "CvTPXI8wB8C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "     print(token.text)"
      ],
      "metadata": {
        "id": "NAu4ewGZB82h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        " if nlp.vocab[token.text].is_stop:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "id": "LwmKkYP7CDCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  if not nlp.vocab[token.text].is_stop:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "id": "khA2f9V9CM96"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}